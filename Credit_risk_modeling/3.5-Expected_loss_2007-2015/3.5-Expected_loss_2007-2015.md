

```python
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
import seaborn as sns

sns.set()

pd.options.display.max_rows = None
pd.options.display.max_columns = None
```


```python
loan_data_preprocessed = pd.read_csv('loan_data_2007-2015_preprocessed.csv', index_col=0)
loan_data_preprocessed.shape
```

    /Users/omaromeiri/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (20,48,56) have mixed types. Specify dtype option on import or set low_memory=False.
      interactivity=interactivity, compiler=compiler, result=result)





    (887379, 207)




```python
loan_data_preprocessed.index
```




    Int64Index([     0,      1,      2,      3,      4,      5,      6,      7,
                     8,      9,
                ...
                887369, 887370, 887371, 887372, 887373, 887374, 887375, 887376,
                887377, 887378],
               dtype='int64', length=887379)




```python
vars_to_use = pickle.load(open('vars_usable_preprocessing.pickle', 'rb'))

len(vars_to_use)
```




    50




```python
'''
    Popping this variable from the vars list because it has only 0 values for this dataset,
    and will cause a SINGULAR MATRIX ERROR while trying to perform the transformations for the p-value calculations
'''

vars_to_use.pop(7)
```




    'home_ownership:ANY'




```python
ref_vars = ['grade:G', 'home_ownership:RENT', 'verification_status:Verified', 'purpose:credit_card', 'initial_list_status:f']
```


```python
loan_data_preprocessed['mths_since_last_delinq'].fillna(0, inplace=True)
loan_data_preprocessed['mths_since_last_record'].fillna(0, inplace=True)
```


```python
loan_data_preprocessed_lgd_ead = loan_data_preprocessed[vars_to_use]
loan_data_preprocessed_lgd_ead.shape
```




    (887379, 49)




```python
loan_data_preprocessed_lgd_ead.drop(ref_vars, axis=1, inplace=True)
loan_data_preprocessed_lgd_ead.shape
```

    /Users/omaromeiri/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
      errors=errors)





    (887379, 44)



### LGD = 1 - recovery_rate


```python
from sklearn import linear_model
import scipy.stats as stat

class LogisticRegression_with_p_values:
    
    def __init__(self,*args,**kwargs):
        self.model = linear_model.LogisticRegression(*args,**kwargs)
        
    def fit(self,X,y):
        self.model.fit(X,y)
        
        #### Get p-values for the fitted model ####
        denom = (2.0 * (1.0 + np.cosh(self.model.decision_function(X))))
        denom = np.tile(denom,(X.shape[1],1)).T
        F_ij = np.dot((X / denom).T,X)
        Cramer_Rao = np.linalg.inv(F_ij)
        sigma_estimates = np.sqrt(np.diagonal(Cramer_Rao))
        z_scores = self.model.coef_[0] / sigma_estimates
        p_values = [stat.norm.sf(abs(x)) * 2 for x in z_scores]
        
        self.coef_ = self.model.coef_
        self.intercept_ = self.model.intercept_
        self.p_values = p_values
```


```python


class LinearRegression(linear_model.LinearRegression):
    def __init__(self, fit_intercept=True, normalize=True, copy_X=True, n_jobs=1):
        self.fit_intercept = fit_intercept
        self.normalize = normalize
        self.copy_X = copy_X
        self.n_jobs = n_jobs
        
    def fit(self, X, y, n_jobs=1):
        self = super(LinearRegression, self).fit(X, y, n_jobs)
        sse = np.sum((self.predict(X) - y) ** 2, axis=0) / float(X.shape[0] - X.shape[1])
        se = np.array([np.sqrt(np.diagonal(sse * np.linalg.inv(np.dot(X.T, X))))])
        self.t = self.coef_ / se
        self.p = np.squeeze(2 * (1 - stat.t.cdf(np.abs(self.t), y.shape[0] - X.shape[1])))
        return self
```


```python
lgd_log_reg = pickle.load(open('model_LGD_log_reg_2007-2015.sav', 'rb'))
```


```python
recovery_rate_binary = lgd_log_reg.model.predict(loan_data_preprocessed_lgd_ead)
```


```python
lgd_lin_reg = pickle.load(open('model_LGD_lin_reg_2007-2015.sav', 'rb'))
```


```python
predicted_recovery_rate_numerical = lgd_lin_reg.predict(loan_data_preprocessed_lgd_ead)
```


```python
loan_data_preprocessed['recovery_rate'] = np.multiply(recovery_rate_binary, predicted_recovery_rate_numerical) 
```


```python
loan_data_preprocessed['recovery_rate'] = loan_data_preprocessed['recovery_rate'].apply(lambda x: 0 if x <= 0 else (1 if x >=1 else x))
```


```python
loan_data_preprocessed['recovery_rate'].describe()
```




    count    887379.000000
    mean          0.044935
    std           0.057267
    min           0.000000
    25%           0.000000
    50%           0.000000
    75%           0.103493
    max           0.647178
    Name: recovery_rate, dtype: float64



## LDG calc


```python
loan_data_preprocessed['LGD'] = 1 - loan_data_preprocessed['recovery_rate']
loan_data_preprocessed['LGD'].describe()
```




    count    887379.000000
    mean          0.955065
    std           0.057267
    min           0.352822
    25%           0.896507
    50%           1.000000
    75%           1.000000
    max           1.000000
    Name: LGD, dtype: float64




```python
plt.figure(figsize=(10,6))
sns.distplot(loan_data_preprocessed['LGD'])
```




    <matplotlib.axes._subplots.AxesSubplot at 0x1a47e2f748>




![png](output_21_1.png)


### EAD


```python
ead_lin_reg = pickle.load(open('model_EAD_lin_reg_2007-2015.sav', 'rb'))
```


```python
loan_data_preprocessed['CCF'] = ead_lin_reg.predict(loan_data_preprocessed_lgd_ead)
```


```python
loan_data_preprocessed['CCF'] = loan_data_preprocessed['CCF'].apply(lambda x: 0 if x <= 0 else (1 if x >=1 else x))
```


```python
loan_data_preprocessed['CCF'].describe()
```




    count    887379.000000
    mean          0.766415
    std           0.104773
    min           0.305311
    25%           0.697305
    50%           0.764600
    75%           0.837171
    max           1.000000
    Name: CCF, dtype: float64




```python
loan_data_preprocessed['EAD'] = loan_data_preprocessed['CCF'] * loan_data_preprocessed['funded_amnt']
loan_data_preprocessed['EAD'].describe()
```




    count    887379.000000
    mean      11569.989311
    std        7282.366320
    min         190.860161
    25%        5888.827433
    50%       10008.818526
    75%       15809.637282
    max       35000.000000
    Name: EAD, dtype: float64



## PD


```python
train = pd.read_csv('loan_data_train_dataset_2007-2015.csv', index_col=0)
print(train.shape)

test = pd.read_csv('loan_data_test_dataset_2007-2015.csv', index_col=0)
print(test.shape)

loan_data_pd = pd.concat([train, test], axis=0)
loan_data_pd.shape
```

    /Users/omaromeiri/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (56) have mixed types. Specify dtype option on import or set low_memory=False.
      interactivity=interactivity, compiler=compiler, result=result)


    (709903, 319)
    (177476, 309)


    /Users/omaromeiri/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
    of pandas will change to not sort by default.
    
    To accept the future behavior, pass 'sort=False'.
    
    To retain the current behavior and silence the warning, pass 'sort=True'.
    
      import sys





    (887379, 319)




```python
del train
del test
```


```python
vars_to_use = pickle.load(open('vars_significant_PD_model_2007-2015.pickle', 'rb'))
print(len(vars_to_use))
      
ref_vars = pickle.load(open('vars_significant_reference_PD_model_2007-2015.pickle', 'rb'))
print(len(ref_vars))

pd_log_reg = pickle.load(open('model_PD_log_reg_2007-2015.pickle', 'rb'))
```

    93
    18



```python
loan_data_pd = loan_data_pd[vars_to_use]
loan_data_pd.shape
```




    (887379, 93)




```python
loan_data_pd['PD'] = pd_log_reg.model.predict_proba(loan_data_pd)[:,0]
```

    /Users/omaromeiri/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
      """Entry point for launching an IPython kernel.



```python
loan_data_pd['PD'].describe()
```




    count    887379.000000
    mean          0.068452
    std           0.078500
    min           0.000095
    25%           0.010433
    50%           0.042397
    75%           0.100042
    max           0.981816
    Name: PD, dtype: float64




```python
sns.distplot(loan_data_pd['PD'])
```




    <matplotlib.axes._subplots.AxesSubplot at 0x1a4abe21d0>




![png](output_35_1.png)



```python
loan_data_preprocessed_new = pd.concat([loan_data_preprocessed, loan_data_pd['PD']], axis=1)
loan_data_preprocessed_new.shape
```




    (887379, 212)




```python
loan_data_preprocessed_new['EL'] = loan_data_preprocessed_new['PD'] * loan_data_preprocessed_new['LGD'] * loan_data_preprocessed_new['EAD']
```


```python
sns.distplot(loan_data_preprocessed_new['EL'])
loan_data_preprocessed_new['EL'].describe()
```




    count    887379.000000
    mean        679.615650
    std         960.662573
    min           0.131845
    25%          90.813786
    50%         329.963806
    75%         864.661963
    max       20615.271240
    Name: EL, dtype: float64




![png](output_38_1.png)


* PD  : The likelihood of the inability to repay the debt in full or in time
* LGD : The share of an asset that is lost when a borrower defaults (the proportion of the total exposure that cannot be recovered)
* EAD : The total value that a lender is exposed to when a borrower defaults (The maximum that a lender can lose whae a borrower defaults)


```python
loan_data_preprocessed_new[['funded_amnt', 'PD', 'LGD', 'EAD', 'EL']].head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>funded_amnt</th>
      <th>PD</th>
      <th>LGD</th>
      <th>EAD</th>
      <th>EL</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5000</td>
      <td>0.159358</td>
      <td>0.921422</td>
      <td>2892.329049</td>
      <td>424.697844</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2500</td>
      <td>0.268171</td>
      <td>0.931517</td>
      <td>1874.555727</td>
      <td>468.274693</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2400</td>
      <td>0.215569</td>
      <td>0.924823</td>
      <td>1524.862134</td>
      <td>304.001535</td>
    </tr>
    <tr>
      <th>3</th>
      <td>10000</td>
      <td>0.205805</td>
      <td>0.914441</td>
      <td>6525.882514</td>
      <td>1228.145814</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3000</td>
      <td>0.110028</td>
      <td>0.924063</td>
      <td>2084.584397</td>
      <td>211.946024</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5000</td>
      <td>0.142845</td>
      <td>0.929354</td>
      <td>2999.804927</td>
      <td>398.236060</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7000</td>
      <td>0.238679</td>
      <td>0.921985</td>
      <td>4923.076846</td>
      <td>1083.362971</td>
    </tr>
    <tr>
      <th>7</th>
      <td>3000</td>
      <td>0.323411</td>
      <td>0.919925</td>
      <td>2016.814244</td>
      <td>600.030797</td>
    </tr>
    <tr>
      <th>8</th>
      <td>5600</td>
      <td>0.383604</td>
      <td>0.905868</td>
      <td>4675.369734</td>
      <td>1624.666253</td>
    </tr>
    <tr>
      <th>9</th>
      <td>5375</td>
      <td>0.130606</td>
      <td>0.930632</td>
      <td>3783.110112</td>
      <td>459.821829</td>
    </tr>
  </tbody>
</table>
</div>




```python
import locale

portfolio_EL = loan_data_preprocessed_new['EL'].sum()

locale.setlocale(locale.LC_ALL, 'en_US')
print(f'The whole portfolio Expected Loss is: ',locale.currency(portfolio_EL, grouping=True))
```

    The whole portfolio Expected Loss is:  $603,076,655.85



```python
total_funded_amount = loan_data_preprocessed_new['funded_amnt'].sum()
print("The bank's total funding amount is", locale.currency(total_funded_amount, grouping=True))
```

    The bank's total funding amount is $13,081,632,625.00


#### A bank usually holds 10% of its assets in capital. EL should be less than 0.1 * total_funded_amnt


Observed portfooio EL should be in the range of 2% and 10%, depending on this value, the bank's management can alter its strategy, giving more loans if the ratio is low or restricting loans if the portfolio EL is too high


```python
from colorama import Fore, Style

capital_adequacy_ratio = portfolio_EL / total_funded_amount

if capital_adequacy_ratio > 0.10:
    print("This bank's strategy is aggressive, their EL is " + Fore.RED+f"{round(capital_adequacy_ratio*100,3)}%" + Style.RESET_ALL+ " of the total funded amount")

if capital_adequacy_ratio < 0.10 and capital_adequacy_ratio > 0.05:
    print(f"This bank's strategy is in the normal range, their EL is " + Fore.YELLOW+ f"{round(capital_adequacy_ratio*100,3)}%" +Style.RESET_ALL + " of the total funded amount")

if capital_adequacy_ratio < 0.05:
    print(f"This bank's strategy is conservative, their EL is " + Fore.GREEN+ f"{round(capital_adequacy_ratio*100,3)}%" +Style.RESET_ALL + " of the total funded amount")


```

    This bank's strategy is conservative, their EL is [32m4.61%[0m of the total funded amount



```python

```
